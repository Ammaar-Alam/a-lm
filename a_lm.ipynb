{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEm1E2aMX66V"
      },
      "source": [
        "# a-lm colab training\n",
        "\n",
        "This notebook runs a full from-scratch pretrain on Colab using the larger `nano` config and the Colab corpus preset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGJWS3ONX66W"
      },
      "source": [
        "## Optional drive mount\n",
        "Use this if your repo or outputs live on Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_dfEgMyKX66W"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhi1JU_QX66W"
      },
      "source": [
        "## Locate or clone the repo\n",
        "If you already uploaded the repo, this will use it. Otherwise it clones into `/content/a-lm`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aYYvUd7X66W",
        "outputId": "58c0aba4-b0b4-4f7a-f71e-7a4b799aa642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/a-lm'...\n",
            "remote: Enumerating objects: 635, done.\u001b[K\n",
            "remote: Counting objects: 100% (635/635), done.\u001b[K\n",
            "remote: Compressing objects: 100% (381/381), done.\u001b[K\n",
            "remote: Total 635 (delta 383), reused 473 (delta 222), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (635/635), 148.38 KiB | 18.55 MiB/s, done.\n",
            "Resolving deltas: 100% (383/383), done.\n",
            "/content/a-lm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "repo_candidates = [\"/content/a-lm\", \"/content/drive/MyDrive/a-lm\"]\n",
        "repo_path = None\n",
        "for candidate in repo_candidates:\n",
        "    if os.path.isdir(candidate):\n",
        "        repo_path = candidate\n",
        "        break\n",
        "\n",
        "if repo_path is None:\n",
        "    repo_path = \"/content/a-lm\"\n",
        "    !git clone https://github.com/ammaar-alam/a-lm.git {repo_path}\n",
        "\n",
        "%cd {repo_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOHuhwrfX66W",
        "outputId": "eb64211e-c3ef-485a-e664-a6d2b39bec74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next: run the 'Install pinned dependencies' cell below. Restart only if Colab warns about imports. Then continue to 'Hugging Face login' and 'Start pretraining'.\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Next: run the 'Install pinned dependencies' cell below.\"\n",
        "    \" Restart only if Colab warns about imports.\"\n",
        "    \" Then continue to 'Hugging Face login' and 'Start pretraining'.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv17Ug74X66W"
      },
      "source": [
        "## Install pinned dependencies\n",
        "These versions avoid Colab crashes and keep `transformers` compatibility.\n",
        "This cell intentionally does **not** downgrade `numpy` (downgrades force restarts and conflict with Colab preinstalls).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89SZk8gX66X",
        "outputId": "60d9677e-8e9f-46c2-ce6d-b7d8364e6040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub<1.0 in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Collecting datasets<3,>=2.19\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyarrow<19,>=15.0.2 in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.12/dist-packages (2025.3.0)\n",
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2026.1.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<3,>=2.19) (2.0.2)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<3,>=2.19) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<3,>=2.19) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<3,>=2.19) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<3,>=2.19) (0.70.16)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub<1.0)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets<3,>=2.19) (3.13.3)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs) (4.4.2)\n",
            "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2025.12.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading gcsfs-2025.10.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading gcsfs-2025.9.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading gcsfs-2025.7.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading gcsfs-2025.5.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.5.0.post1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.5.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: pip is still looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading gcsfs-2025.3.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.3.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.3.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading gcsfs-2025.2.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2024.12.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading gcsfs-2024.10.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading gcsfs-2024.9.0.post1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading gcsfs-2024.6.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from gcsfs) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from gcsfs) (3.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<3,>=2.19) (1.22.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs) (6.2.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub<1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub<1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub<1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub<1.0) (2026.1.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (2.29.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (2.8.0)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<3,>=2.19) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<3,>=2.19) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<3,>=2.19) (2025.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs) (1.27.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<3,>=2.19) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.3.1)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gcsfs-2024.6.1-py2.py3-none-any.whl (34 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets, gcsfs\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: gcsfs\n",
            "    Found existing installation: gcsfs 2025.3.0\n",
            "    Uninstalling gcsfs-2025.3.0:\n",
            "      Successfully uninstalled gcsfs-2025.3.0\n",
            "Successfully installed datasets-2.21.0 fsspec-2024.6.1 gcsfs-2024.6.1\n",
            "Obtaining file:///content/a-lm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: a-lm\n",
            "  Building editable for a-lm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for a-lm: filename=a_lm-0.1.0-0.editable-py3-none-any.whl size=12804 sha256=a6cf9c4dee56979078cfe52f5375a69b315e4f840e6310096efd0fd94ccd0a8a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mql9j3fp/wheels/ef/54/1b/8efeaeaddcf19a3d45f22bca6f53da044937f90e80a0172597\n",
            "Successfully built a-lm\n",
            "Installing collected packages: a-lm\n",
            "Successfully installed a-lm-0.1.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U \"huggingface_hub<1.0\" \"datasets>=2.19,<3\" \"pyarrow>=15.0.2,<19\" \\\n",
        "  \"gcsfs\" \"tokenizers>=0.22.0,<=0.23.0\"\n",
        "%pip install -e . --no-deps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTpq2KZCX66X"
      },
      "source": [
        "## Optional: enable verbose training logs\n",
        "By default the progress bar updates live. If you want per-step log lines, run this cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTSMLMbDX66X",
        "outputId": "04ed4e9a-a4fc-450f-f2ac-80244d3c6bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote configs/train_colab_verbose.yaml\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "Path(\"configs/train_colab_verbose.yaml\").write_text(\"\"\"\n",
        "optim:\n",
        "  name: adamw\n",
        "  lr: 3e-4\n",
        "  betas: [0.9, 0.95]\n",
        "  weight_decay: 0.1\n",
        "  eps: 1e-8\n",
        "\n",
        "scheduler:\n",
        "  name: cosine\n",
        "  warmup_steps: 1000\n",
        "  max_steps: 20000\n",
        "\n",
        "training:\n",
        "  micro_batch_size: 4\n",
        "  gradient_accumulation: 8\n",
        "  max_steps: 20000\n",
        "  checkpoint_interval: 500\n",
        "  gradient_clip_norm: 0.5\n",
        "  mixed_precision: fp16\n",
        "  grad_checkpointing: false\n",
        "  seed: 1337\n",
        "  dataloader_workers: 2\n",
        "\n",
        "logging:\n",
        "  log_interval: 1\n",
        "  rich_progress: false\n",
        "\"\"\")\n",
        "print(\"Wrote configs/train_colab_verbose.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCpZPfk3X66X"
      },
      "source": [
        "## Hugging Face login\n",
        "Paste your token when prompted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a7bzppoHX66X"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "login(userdata.get('HF_TOKEN'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsyOHOVX66X"
      },
      "source": [
        "## GPU check\n",
        "Make sure CUDA is available before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQlmAlIzX66X",
        "outputId": "08ca2ca0-c3a4-42ac-a06e-fc6a6a89570e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 29 21:37:00 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA H100 80GB HBM3          Off |   00000000:04:00.0 Off |                    0 |\n",
            "| N/A   31C    P0             69W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "2.9.0+cu126 True 12.6\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "!nvidia-smi\n",
        "print(torch.__version__, torch.cuda.is_available(), torch.version.cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAPAD4fsX66X"
      },
      "source": [
        "## Start pretraining\n",
        "Stores the run id in `LAST_RUN.txt` so later cells can resume or chat.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "QNiV26ASX66X",
        "outputId": "5c23cd94-3dd0-4c9a-d6b4-5dc06e5eb7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run: 20260129-213701\n",
            "using verbose logging config\n",
            "command: make colab-pretrain RUN=20260129-213701 TRAIN_CFG=configs/train_colab_verbose.yaml\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "make failed with exit code 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3778558377.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"make failed with exit code {result.returncode}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: make failed with exit code 2"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "run_id = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "Path(\"LAST_RUN.txt\").write_text(run_id)\n",
        "print(\"run:\", run_id)\n",
        "\n",
        "train_cfg = \"configs/train_colab.yaml\"\n",
        "if Path(\"configs/train_colab_verbose.yaml\").exists():\n",
        "    train_cfg = \"configs/train_colab_verbose.yaml\"\n",
        "    print(\"using verbose logging config\")\n",
        "\n",
        "cmd = [\"make\", \"colab-pretrain\", f\"RUN={run_id}\", f\"TRAIN_CFG={train_cfg}\"]\n",
        "print(\"command:\", \" \".join(cmd))\n",
        "result = subprocess.run(cmd)\n",
        "if result.returncode != 0:\n",
        "    raise RuntimeError(f\"make failed with exit code {result.returncode}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDv7iN2TX66X"
      },
      "source": [
        "## Chat with the latest checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12PgogMqX66Y"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "run_id = Path(\"LAST_RUN.txt\").read_text().strip()\n",
        "print(\"using run\", run_id)\n",
        "!make chat RUN={run_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1qMPPsnX66Y"
      },
      "source": [
        "## RLVR post-training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otBTVf_RX66Y"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "run_id = Path(\"LAST_RUN.txt\").read_text().strip()\n",
        "print(\"using run\", run_id)\n",
        "\n",
        "!make rlvr-data\n",
        "!make rlvr-train RUN={run_id}\n",
        "!make chat RUN={run_id} CHECKPOINT=runs/{run_id}/rlvr/ckpt-last.pt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "H100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
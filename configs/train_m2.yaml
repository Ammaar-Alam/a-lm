# quicker defaults for laptop iteration
optim:
  name: adamw
  lr: 3e-4
  betas: [0.9, 0.95]
  weight_decay: 0.1
  eps: 1e-8

scheduler:
  name: cosine
  warmup_steps: 200
  max_steps: 5000

training:
  micro_batch_size: 4
  gradient_accumulation: 4
  max_steps: 5000
  checkpoint_interval: 250
  gradient_clip_norm: 0.5
  mixed_precision: fp16
  grad_checkpointing: false
  seed: 1337
  dataloader_workers: 1

logging:
  log_interval: 10
  rich_progress: true


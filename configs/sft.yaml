optim:
  name: adamw
  lr: 1e-5
  betas: [ 0.9, 0.95 ]
  weight_decay: 0.0
  eps: 1e-8

scheduler:
  name: cosine
  warmup_steps: 200
  max_steps: 4500

training:
  micro_batch_size: 8
  gradient_accumulation: 4
  global_batch_size: 32
  seq_len: 384
  checkpoint_interval: 750
  gradient_clip_norm: 1.0
  mixed_precision: fp32
  dataloader_workers: 1
  prefetch_factor: 4
  max_steps: 4500
  seed: 1337

logging:
  log_interval: 20
  output_dir: runs/pico-sft
  rich_progress: true
